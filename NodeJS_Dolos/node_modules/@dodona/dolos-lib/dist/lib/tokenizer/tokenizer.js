"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.Tokenizer = void 0;
const tokenizedFile_1 = require("../file/tokenizedFile");
class Tokenizer {
    /**
     * Returns a tokenized version of the given file.
     *
     * @param file The file to parse
     */
    tokenizeFile(file) {
        const [ast, mapping] = this.tokenizeWithMapping(file.content);
        return new tokenizedFile_1.TokenizedFile(file, ast, mapping);
    }
    /**
     * Returns a stringified version of the tokens in the buffer
     *
     * @param text The buffer to stringify
     */
    tokenize(text) {
        return Array.of(...this.generateTokens(text)).join();
    }
    /**
     * Runs the stringifier on a given buffer. Returns a tuple containing the
     * stringified version and an array containing a mapping from each token to
     * the corresponding token in the original buffer.
     *
     * @param text The text buffer to stringify
     */
    tokenizeWithMapping(text) {
        const resultTokens = [];
        const positionMapping = [];
        for (const { token, location } of this.generateTokens(text)) {
            resultTokens.push(token);
            positionMapping.push(location);
        }
        return [resultTokens, positionMapping];
    }
    /**
     * Returns a new token-object.
     * Just a shorthand for {token: ..., location: ...}.
     *
     * @param token the text of the token
     * @param location the location of the token
     */
    newToken(token, location) {
        return { token, location };
    }
}
exports.Tokenizer = Tokenizer;
//# sourceMappingURL=tokenizer.js.map